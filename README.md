# Big Data 1 - ADA

#### 1. **Descrição**<br>
Este repositório contém o projeto prático do módulo: Big Data I. Neste projeto aplicaremos as técnicas aprendidas em aula para criarmos processo de ETL em uma plataforma de Cloud.

#### 2. **Objetivo**<br> 
Construir um pipeline de ETL (`Extract-Transform-Load`) para a construção de um Data Warehouse na plataforma DataBricks Community. 

#### 3. **Etapas**<br>
1 - Exportar as tabelas da base em .CSV.

2 - Carregar para camada Raw de um Data Lake no DBFS (botão de upload).

3 - Salvar dados em formato parquet em uma segunda camada, trusted.

4 - Modelar a base de dados em formato Star Schema ou Snowflake para criação de um Data Warehouse.

Opcional - Criar em uma terceira camada, refined, um Data Lakehouse com o modelo do passo anterior, através de Delta Tables, com ao menos duas tabelas agregadas.


###Nome da Base de Dados: IMDB 5000 Movie Dataset

###Link da base de dados IMDB 5000 Movie Dataset: https://www.kaggle.com/datasets/carolzhangdc/imdb-5000-movie-dataset
